Batch Size: 1, Warmup: 20 iters, Benchmark: 30 iters
Warmup with 20 Iters
Running 30 Iters
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
autograd::engine::evaluate_function: ConvolutionBack...         1.18%      14.272ms        26.16%     316.812ms     199.253us       0.000us         0.00%     102.832ms      64.674us          1590  
                                   ConvolutionBackward0         0.49%       5.978ms        24.29%     294.233ms     185.052us       0.000us         0.00%      99.876ms      62.815us          1590  
                             aten::convolution_backward        17.72%     214.596ms        23.80%     288.255ms     181.292us      99.876ms        28.28%      99.876ms      62.815us          1590  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      82.811ms        23.45%      82.811ms       5.360us         15450  
                                             aten::add_         7.96%      96.402ms        14.52%     175.858ms      11.747us      79.855ms        22.61%      79.855ms       5.334us         14970  
                                Optimizer.step#SGD.step         5.86%      71.033ms        19.78%     239.609ms       7.987ms       0.000us         0.00%      76.607ms       2.554ms            30  
                                           aten::conv2d         0.32%       3.917ms        14.13%     171.160ms     107.648us       0.000us         0.00%      46.068ms      28.974us          1590  
                                      aten::convolution         0.89%      10.761ms        13.81%     167.243ms     105.184us       0.000us         0.00%      46.068ms      28.974us          1590  
                                     aten::_convolution         0.65%       7.902ms        12.92%     156.482ms      98.416us       0.000us         0.00%      46.068ms      28.974us          1590  
                                aten::cudnn_convolution         9.56%     115.737ms        12.27%     148.580ms      93.447us      46.068ms        13.04%      46.068ms      28.974us          1590  
void cudnn::ops::nchwToNhwcKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us      37.958ms        10.75%      37.958ms       8.726us          4350  
                                       aten::batch_norm         0.25%       3.025ms        10.75%     130.231ms      81.906us       0.000us         0.00%      32.240ms      20.277us          1590  
                           aten::_batch_norm_impl_index         0.46%       5.617ms        10.50%     127.206ms      80.004us       0.000us         0.00%      32.240ms      20.277us          1590  
                                aten::native_batch_norm         3.14%      38.001ms         9.26%     112.216ms      70.576us      21.125ms         5.98%      32.240ms      20.277us          1590  
autograd::engine::evaluate_function: torch::autograd...         1.29%      15.616ms         7.24%      87.686ms      18.154us       0.000us         0.00%      25.820ms       5.346us          4830  
                        torch::autograd::AccumulateGrad         1.13%      13.676ms         5.95%      72.070ms      14.921us       0.000us         0.00%      25.820ms       5.346us          4830  
                                             aten::mul_         2.79%      33.804ms         4.85%      58.760ms      12.166us      25.470ms         7.21%      25.470ms       5.273us          4830  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      25.470ms         7.21%      25.470ms       5.273us          4830  
autograd::engine::evaluate_function: NativeBatchNorm...         1.02%      12.364ms         6.98%      84.504ms      53.147us       0.000us         0.00%      23.057ms      14.501us          1590  
                               NativeBatchNormBackward0         0.49%       5.932ms         5.96%      72.140ms      45.371us       0.000us         0.00%      23.057ms      14.501us          1590  
                       aten::native_batch_norm_backward         1.71%      20.712ms         5.47%      66.208ms      41.640us      23.057ms         6.53%      23.057ms      14.501us          1590  
void at::native::batch_norm_backward_kernel<c10::Hal...         0.00%       0.000us         0.00%       0.000us       0.000us      23.057ms         6.53%      23.057ms      14.501us          1590  
                                            aten::fill_         1.56%      18.864ms         3.58%      43.418ms       8.879us      22.595ms         6.40%      22.595ms       4.621us          4890  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      22.595ms         6.40%      22.595ms       4.621us          4890  
                                            aten::zero_         1.66%      20.131ms         5.21%      63.115ms      12.828us       0.000us         0.00%      22.474ms       4.568us          4920  
                      Optimizer.zero_grad#SGD.zero_grad         1.96%      23.794ms         7.14%      86.476ms       2.883ms       0.000us         0.00%      22.283ms     742.767us            30  
void cudnn::ops::nhwcToNchwKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us      16.826ms         4.76%      16.826ms       8.248us          2040  
void at::native::batch_norm_transform_input_kernel<c...         0.00%       0.000us         0.00%       0.000us       0.000us      13.439ms         3.80%      13.439ms       8.452us          1590  
                                            aten::copy_         1.22%      14.782ms         2.38%      28.818ms      17.465us      11.498ms         3.26%      11.498ms       6.968us          1650  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      11.115ms         3.15%      11.115ms       6.991us          1590  
     autograd::engine::evaluate_function: ReluBackward0         0.57%       6.924ms         2.96%      35.814ms      24.363us       0.000us         0.00%       8.536ms       5.807us          1470  
                                          ReluBackward0         0.40%       4.835ms         2.39%      28.890ms      19.653us       0.000us         0.00%       8.536ms       5.807us          1470  
                               aten::threshold_backward         1.25%      15.167ms         1.99%      24.055ms      16.364us       8.536ms         2.42%       8.536ms       5.807us          1470  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.536ms         2.42%       8.536ms       5.807us          1470  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.298ms         2.35%       8.298ms       5.645us          1470  
                                            aten::relu_         1.03%      12.536ms         2.56%      31.045ms      21.119us       0.000us         0.00%       8.292ms       5.641us          1470  
                                       aten::clamp_min_         0.79%       9.551ms         1.53%      18.509ms      12.591us       8.292ms         2.35%       8.292ms       5.641us          1470  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       7.686ms         2.18%       7.686ms       4.834us          1590  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       5.137ms         1.45%       5.137ms      24.462us           210  
sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us       5.072ms         1.44%       5.072ms      24.152us           210  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       4.874ms         1.38%       4.874ms      20.308us           240  
void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s168...         0.00%       0.000us         0.00%       0.000us       0.000us       4.593ms         1.30%       4.593ms      19.137us           240  
void cutlass::Kernel<cutlass_80_wmma_tensorop_f16_s1...         0.00%       0.000us         0.00%       0.000us       0.000us       4.527ms         1.28%       4.527ms      25.150us           180  
void cudnn::cnn::reduce_wgrad_nchw_helper<float, __h...         0.00%       0.000us         0.00%       0.000us       0.000us       4.257ms         1.21%       4.257ms       6.450us           660  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       3.765ms         1.07%       3.765ms      25.100us           150  
void cutlass::Kernel<cutlass_80_tensorop_f16_s16816g...         0.00%       0.000us         0.00%       0.000us       0.000us       3.725ms         1.05%       3.725ms      20.694us           180  
void cutlass::Kernel<cutlass_80_wmma_tensorop_s16161...         0.00%       0.000us         0.00%       0.000us       0.000us       3.649ms         1.03%       3.649ms      15.204us           240  
void cutlass::Kernel<cutlass_80_wmma_tensorop_f16_s1...         0.00%       0.000us         0.00%       0.000us       0.000us       3.150ms         0.89%       3.150ms      21.000us           150  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       3.051ms         0.86%       3.051ms      14.529us           210  
void cutlass::Kernel<cutlass_80_tensorop_f16_s16816g...         0.00%       0.000us         0.00%       0.000us       0.000us       2.959ms         0.84%       2.959ms      19.727us           150  
                                              aten::add         0.45%       5.415ms         0.69%       8.307ms      17.306us       2.956ms         0.84%       2.956ms       6.158us           480  
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       2.932ms         0.83%       2.932ms      12.217us           240  
sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.922ms         0.83%       2.922ms      16.233us           180  
sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.644ms         0.75%       2.644ms      29.378us            90  
void cutlass::Kernel<cutlass_80_wmma_tensorop_s16161...         0.00%       0.000us         0.00%       0.000us       0.000us       2.640ms         0.75%       2.640ms      14.667us           180  
void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s168...         0.00%       0.000us         0.00%       0.000us       0.000us       2.534ms         0.72%       2.534ms      14.078us           180  
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us       2.397ms         0.68%       2.397ms      11.414us           210  
void cutlass::Kernel<cutlass_80_wmma_tensorop_s16161...         0.00%       0.000us         0.00%       0.000us       0.000us       2.195ms         0.62%       2.195ms      14.633us           150  
void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s168...         0.00%       0.000us         0.00%       0.000us       0.000us       2.081ms         0.59%       2.081ms      23.122us            90  
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       2.057ms         0.58%       2.057ms      11.428us           180  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       1.814ms         0.51%       1.814ms      15.117us           120  
sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.701ms         0.48%       1.701ms      18.900us            90  
    autograd::engine::evaluate_function: AddmmBackward0         0.04%     477.000us         0.57%       6.939ms     231.300us       0.000us         0.00%       1.686ms      56.200us            30  
ampere_s16816gemm_fp16_64x64_sliced1x2_ldg8_stages_6...         0.00%       0.000us         0.00%       0.000us       0.000us       1.667ms         0.47%       1.667ms      27.783us            60  
void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s168...         0.00%       0.000us         0.00%       0.000us       0.000us       1.517ms         0.43%       1.517ms      16.856us            90  
ampere_fp16_scudnn_fp16_128x64_relu_xregs_large_nn_v...         0.00%       0.000us         0.00%       0.000us       0.000us       1.493ms         0.42%       1.493ms      49.767us            30  
                                         AddmmBackward0         0.04%     525.000us         0.46%       5.606ms     186.867us       0.000us         0.00%       1.435ms      47.833us            30  
                                               aten::mm         0.16%       1.905ms         0.37%       4.464ms      74.400us       1.052ms         0.30%       1.435ms      23.917us            60  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       1.390ms         0.39%       1.390ms      23.167us            60  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us       1.340ms         0.38%       1.340ms      14.889us            90  
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us       1.272ms         0.36%       1.272ms      10.600us           120  
autograd::engine::evaluate_function: MaxPool2DWithIn...         0.01%     181.000us         0.12%       1.416ms      47.200us       0.000us         0.00%       1.135ms      37.833us            30  
                          MaxPool2DWithIndicesBackward0         0.01%     146.000us         0.10%       1.235ms      41.167us       0.000us         0.00%       1.135ms      37.833us            30  
                 aten::max_pool2d_with_indices_backward         0.04%     468.000us         0.09%       1.089ms      36.300us     944.000us         0.27%       1.135ms      37.833us            30  
sm80_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize32x32x...         0.00%       0.000us         0.00%       0.000us       0.000us       1.031ms         0.29%       1.031ms      11.456us            90  
                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     953.000us         0.27%     953.000us       2.647us           360  
void at::native::(anonymous namespace)::max_pool_bac...         0.00%       0.000us         0.00%       0.000us       0.000us     944.000us         0.27%     944.000us      31.467us            30  
void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s168...         0.00%       0.000us         0.00%       0.000us       0.000us     880.000us         0.25%     880.000us      14.667us            60  
ampere_s16816gemm_fp16_64x64_sliced1x2_ldg8_stages_6...         0.00%       0.000us         0.00%       0.000us       0.000us     828.000us         0.23%     828.000us      27.600us            30  
void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s168...         0.00%       0.000us         0.00%       0.000us       0.000us     819.000us         0.23%     819.000us      13.650us            60  
_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitG...         0.00%       0.000us         0.00%       0.000us       0.000us     764.000us         0.22%     764.000us      25.467us            30  
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64...         0.00%       0.000us         0.00%       0.000us       0.000us     753.000us         0.21%     753.000us      12.550us            60  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us     632.000us         0.18%     632.000us      21.067us            30  
                       ampere_fp16_sgemm_fp16_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     534.000us         0.15%     534.000us      17.800us            30  
std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us     518.000us         0.15%     518.000us      17.267us            30  
                                              aten::sum         0.10%       1.215ms         0.14%       1.700ms      28.333us     501.000us         0.14%     501.000us       8.350us            60  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     501.000us         0.14%     501.000us       8.350us            60  
                                           aten::linear         0.01%     148.000us         0.17%       2.084ms      69.467us       0.000us         0.00%     478.000us      15.933us            30  
                                            aten::addmm         0.10%       1.188ms         0.14%       1.657ms      55.233us     478.000us         0.14%     478.000us      15.933us            30  
std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us     478.000us         0.14%     478.000us      15.933us            30  
                                            aten::clone         0.02%     227.000us         0.17%       2.011ms      33.517us       0.000us         0.00%     383.000us       6.383us            60  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     383.000us         0.11%     383.000us       6.383us            60  
                                       aten::max_pool2d         0.01%     140.000us         0.08%     989.000us      32.967us       0.000us         0.00%     380.000us      12.667us            30  
                          aten::max_pool2d_with_indices         0.05%     625.000us         0.07%     849.000us      28.300us     380.000us         0.11%     380.000us      12.667us            30  
void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us     380.000us         0.11%     380.000us      12.667us            30  
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_g...         0.00%       0.000us         0.00%       0.000us       0.000us     380.000us         0.11%     380.000us      12.667us            30  
void cutlass_cudnn::Kernel<cutlass_cudnn::reduction:...         0.00%       0.000us         0.00%       0.000us       0.000us     323.000us         0.09%     323.000us      10.767us            30  
                              aten::adaptive_avg_pool2d         0.01%     104.000us         0.09%       1.128ms      37.600us       0.000us         0.00%     293.000us       9.767us            30  
                                             aten::mean         0.06%     755.000us         0.08%       1.024ms      34.133us     293.000us         0.08%     293.000us       9.767us            30  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     293.000us         0.08%     293.000us       9.767us            30  
void cutlass::Kernel<cutlass_80_wmma_tensorop_f16_s1...         0.00%       0.000us         0.00%       0.000us       0.000us     280.000us         0.08%     280.000us       9.333us            30  
     autograd::engine::evaluate_function: MeanBackward1         0.01%     162.000us         0.13%       1.546ms      51.533us       0.000us         0.00%     220.000us       7.333us            30  
                                          MeanBackward1         0.02%     230.000us         0.11%       1.384ms      46.133us       0.000us         0.00%     220.000us       7.333us            30  
                                              aten::div         0.06%     722.000us         0.08%     987.000us      32.900us     220.000us         0.06%     220.000us       7.333us            30  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     220.000us         0.06%     220.000us       7.333us            30  
void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us     162.000us         0.05%     162.000us       5.400us            30  
                                        aten::ones_like         0.01%     107.000us         0.07%     820.000us      27.333us       0.000us         0.00%     121.000us       4.033us            30  
                                            aten::zeros         0.02%     274.000us         0.04%     432.000us       7.200us       0.000us         0.00%       0.000us       0.000us            60  
                                            aten::empty         5.78%      69.961ms         5.78%      69.961ms       4.351us       0.000us         0.00%       0.000us       0.000us         16080  
                                       cudaLaunchKernel        21.93%     265.613ms        21.93%     265.613ms       5.694us       0.000us         0.00%       0.000us       0.000us         46650  
                                  cudaStreamIsCapturing         0.00%      18.000us         0.00%      18.000us       0.004us       0.000us         0.00%       0.000us       0.000us          4740  
                                  cudaStreamGetPriority         0.00%       9.000us         0.00%       9.000us       0.002us       0.000us         0.00%       0.000us       0.000us          4740  
                       cudaDeviceGetStreamPriorityRange         0.00%       5.000us         0.00%       5.000us       0.001us       0.000us         0.00%       0.000us       0.000us          4740  
                                       aten::empty_like         0.84%      10.219ms         3.21%      38.873ms       6.027us       0.000us         0.00%       0.000us       0.000us          6450  
                                    aten::empty_strided         0.73%       8.807ms         0.73%       8.807ms       5.436us       0.000us         0.00%       0.000us       0.000us          1620  
                                          aten::reshape         0.68%       8.272ms         0.99%      11.935ms       2.486us       0.000us         0.00%       0.000us       0.000us          4800  
                                   aten::_reshape_alias         0.32%       3.831ms         0.32%       3.831ms       0.793us       0.000us         0.00%       0.000us       0.000us          4830  
                                             aten::view         0.18%       2.179ms         0.18%       2.179ms       0.679us       0.000us         0.00%       0.000us       0.000us          3210  
cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.16%       1.965ms         0.16%       1.965ms       0.489us       0.000us         0.00%       0.000us       0.000us          4020  
                                   cudaFuncSetAttribute         0.23%       2.751ms         0.23%       2.751ms       0.435us       0.000us         0.00%       0.000us       0.000us          6330  
                                        cudaMemsetAsync         0.19%       2.251ms         0.19%       2.251ms       6.253us       0.000us         0.00%       0.000us       0.000us           360  
                                          aten::flatten         0.01%      82.000us         0.02%     250.000us       8.333us       0.000us         0.00%       0.000us       0.000us            30  
                                                aten::t         0.04%     494.000us         0.09%       1.057ms       7.047us       0.000us         0.00%       0.000us       0.000us           150  
                                        aten::transpose         0.04%     431.000us         0.05%     563.000us       3.753us       0.000us         0.00%       0.000us       0.000us           150  
                                       aten::as_strided         0.02%     238.000us         0.02%     238.000us       0.992us       0.000us         0.00%       0.000us       0.000us           240  
      autograd::engine::evaluate_function: SumBackward0         0.02%     186.000us         0.05%     554.000us      18.467us       0.000us         0.00%       0.000us       0.000us            30  
                                           SumBackward0         0.01%     135.000us         0.03%     368.000us      12.267us       0.000us         0.00%       0.000us       0.000us            30  
                                           aten::expand         0.02%     287.000us         0.03%     373.000us       6.217us       0.000us         0.00%       0.000us       0.000us            60  
        autograd::engine::evaluate_function: TBackward0         0.01%     139.000us         0.03%     350.000us      11.667us       0.000us         0.00%       0.000us       0.000us            30  
                                             TBackward0         0.00%      50.000us         0.02%     211.000us       7.033us       0.000us         0.00%       0.000us       0.000us            30  
autograd::engine::evaluate_function: ReshapeAliasBac...         0.01%     125.000us         0.03%     343.000us      11.433us       0.000us         0.00%       0.000us       0.000us            30  
                                  ReshapeAliasBackward0         0.00%      57.000us         0.02%     218.000us       7.267us       0.000us         0.00%       0.000us       0.000us            30  
                                               aten::to         0.00%      27.000us         0.00%      27.000us       0.900us       0.000us         0.00%       0.000us       0.000us            30  
      autograd::engine::evaluate_function: AddBackward0         0.13%       1.621ms         0.15%       1.836ms       3.825us       0.000us         0.00%       0.000us       0.000us           480  
                                           AddBackward0         0.02%     215.000us         0.02%     215.000us       0.448us       0.000us         0.00%       0.000us       0.000us           480  
                                  cudaDeviceSynchronize         0.03%     318.000us         0.03%     318.000us      10.258us       0.000us         0.00%       0.000us       0.000us            31  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 1.211s
Self CUDA time total: 353.202ms

Total Time: 14.761865818989463
Throughput: 2.0322634257661663
